import torch

from numpy import ndarray
from torch import nn, tensor
from torchvision import models


class ImageFeatureExtractor(nn.Module):
    """
    
    Wrapper around pretrained ResNet50 model to extract features from images

    Attributes:
        resnet (models.resnet50):   Pretrained ResNet50 model
    
    """

    def __init__(self, embedding_dim: int) -> None:
        """
        
        Constructor for ImageFeatureExtractor

        
        Parameters:
            embedding_dim (int):            The dimension of the embedding layer of LSTMNetwork
        
        """

        super(ImageFeatureExtractor, self).__init__()

        # Initialize ResNet50 model with default weights
        self.resnet = models.resnet50(weights='DEFAULT')

        # Replace fully connected layer to reshape features to embedding dimension
        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, embedding_dim)


    def forward(self, images: tensor) -> tensor:
        """
        
        Handles the forward pass for ImageFeatureExtractor

        
        Parameters:
            images (tensor):    Batch of tensors containing image representations

        
        Returns:
            tensor:     A tensor representing the scores generated by the ResNet50 model

        """

        return self.resnet(images)
    

class LSTMNetwork(nn.Module):
    """
    
    Custom LSTM network to decode image features into generated tokens for captioning

    Attributes:
        embedding (nn.Embedding):   Pretrained embedding layer using Word2Vec embeddings
        lstm (nn.LSTM):             LSTM layer to handle input sequence
        linear (nn.Linear):         Linear layer to handle outputting token scores
    
    """
    def __init__(self, embedding_dim: int, hidden_size: int, embedding_matrix: ndarray) -> None:
        """
        
        Constructor for LSTMNetwork

        
        Parameters:
            embedding_dim (int):            The dimension of the embedding layer of LSTMNetwork
            hidden_size (int):              The number of features in the hidden layer of LSTM
            embedding_matrix (ndarray):     Matrix representing Word2Vec embeddings of tokens in dataset
        
        """
        super(LSTMNetwork, self).__init__()

        # Initialize embedding layer from pretrained word2vec model
        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=True)
        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)
        self.linear = nn.Linear(hidden_size, len(embedding_matrix))


    def forward(self, features: tensor, captions: tensor) -> tensor:
        """
        
        Handles the forward pass for LSTMNetwork

        
        Parameters:
            features (tensor):      Batch of tensors containing feature representation of images
            captions (tensor):      Batch of tensors containing token indices for each caption

        
        Returns:
            tensor:     A tensor representing the scores generated by the model

        """

        # Create embedding tensor from caption tokens
        embeddings = self.embedding(captions)

        # Reshape image features and concatenate image features with embeddings
        features = features.unsqueeze(1)
        inputs = torch.cat((features, embeddings), 1)

        # Pass embeddings and features into lstm layer then linear layer for token scores
        output, _ = self.lstm(inputs)
        output = self.linear(output)

        return output
    

class ImageCaptioningNetwork(nn.Module):
    """
    
    Full network architecture used to extract features from images and
    generate captions using extracted features

    Attributes:
        feature_extractor (ImageFeatureExtractor):  ResNet50 model to extract features from images
        lstm_network (LSTMNetwork):                 LSTM network used to generate captions using image features
    
    """
    def __init__(self, embedding_dim: int, hidden_size: int, embedding_matrix: ndarray) -> None:
        """
        
        Constructor for ImageCaptioningNetwork

        
        Parameters:
            embedding_dim (int):            The dimension of the embedding layer of LSTMNetwork
            hidden_size (int):              The number of features in the hidden layer of LSTM
            embedding_matrix (ndarray):     Matrix representing Word2Vec embeddings of tokens in dataset
        
        """
        super(ImageCaptioningNetwork, self).__init__()

        # Feature extraction network
        self.feature_extractor = ImageFeatureExtractor(embedding_dim)

        # Caption generation network
        self.lstm_network = LSTMNetwork(embedding_dim, hidden_size, embedding_matrix)

    
    def forward(self, images: tensor, captions: tensor) -> tensor:
        """
        
        Handles the forward pass for ImageCaptioningNetwork

        
        Parameters:
            images (tensor):    Batch of tensors containing image representations
            captions (tensor):  Batch of tensors containing caption embeddings

        
        Returns:
            tensor:     A tensor representing the scores generated by the model

        """

        # Generate features from pretrained network
        with torch.no_grad():
            features = self.feature_extractor(images)

        # Generate caption scores from images and captions
        output = self.lstm_network(features, captions)

        return output
    

def load_model(embedding_matrix: ndarray, trained_model_path: str = None) -> ImageCaptioningNetwork:
    """
    
    Load a saved model's state dict if one is passed, otherwise load base model


    Parameters:
        embedding_matrix (ndarray): Matrix consiting ov Word2Vec embeddings for tokens in dictionary
        trained_model_path (str):   Path to pretrained model

    
    Returns:
        ImageCaptioningNetwork: The image captioning model
    
    """

    # Initialize the base image captioning model
    model = ImageCaptioningNetwork(embedding_dim=embedding_matrix.shape[1],
                                       hidden_size=256,
                                       embedding_matrix=embedding_matrix)
    
    # Load state dict of pretrained model if it is passed in
    if trained_model_path:
        model.load_state_dict(torch.load(trained_model_path, weights_only=True))

    return model
